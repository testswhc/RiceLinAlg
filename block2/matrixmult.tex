

\beginedxvertical{Page One}

\beginedxtext{Preliminaries}





At the end of this sequence, and after some practice, you should be able to:

\begin{itemize}
\item Recognize when two matrices can be multiplied.  
\item Calculate the product of two matrices. 
\item Draw parallels between matrix multiplication and composition of linear transformations.
\end{itemize}


For time budgeting purposes, this sequence has X videos totaling X minutes, 
plus some questions.  




\endedxtext

\endedxvertical


\beginedxvertical{Composition of Linear Transformations}



\doedxvideo{Composition of Linear Transformations}{r-gtj-GO9WI}

\beginedxtext{Fundamental Fact of Matrix Multiplication}

{\keya{\bf{Proposition.}}}  
If $S: \R^p \rightarrow \R^n$ and $T: \R^n \rightarrow \R^m$ are linear transformations, then $T\circ S: \R^p \rightarrow \R^m$ is a linear transformation.  

{\keya{\bf{Fundamental Fact of Matrix Multiplication.}}}  
If the $m\times n$ matrix $A$ is the standard matrix for $T: \R^n \rightarrow \R^m$, and the $n\times p$ matrix $B$ is the standard matrix for $S: \R^p \rightarrow \R^n$, then $AB$ will be an $m\times p$ matrix which is the standard matrix for
$T\circ S: \R^p \rightarrow \R^m$.  

(If the number of columns of $A$ is not equal to the number of rows of $B$, then $AB$ is not defined, just as the composition $T\circ S$ would not  be defined.)  

\endedxtext




\endedxvertical



\beginedxvertical{Questions about Composition}






\beginedxproblem{Composing}{\dpa1}

Suppose $T_1: \R^7 \rightarrow \R^4$ and $T_2: \R^3 \rightarrow \R^7$ are both linear transformations.

Is $T_1\circ T_2$ a linear transformation?  

\edXabox{expect="Yes" options="Yes","No"}

Is $T_2\circ T_1$ a linear transformation?  

\edXabox{expect="No" options="Yes","No"}

\edXsolution{Note that $T_1\circ T_2$ first applies $T_2$ and then $T_1$, so we need to check that the image of $T_2$ lies in the domain of $T_1$.  This is true since $T_2$ outputs a vector in $\R^7$, which is the domain of $T_1$.  Then, since $T_1$ and $T_2$ are both linear transformations, so it $T_1\circ T_2$.\\

Now, $T_2\circ T_1$ first applies $T_1$, which outputs a vector in $\R^4$.  It would then apply $T_2$, but this is not possible since the domain of $T_2$ is $\R^3$.
}

\endedxproblem


\beginedxproblem{Matrix Sizes}{\dpa1}

Let $C_1$ be the standard matrix for $T_1$ from the previous question, and let $C_2$ be the
standard matrix for $T_2$.  

What size is $C_1$?  

\edXabox{expect="4 x 7" options="4 x 7","7 x 4"}

What size is $C_2$?  

\edXabox{expect="7 x 3" options="3 x 7","7 x 3"}


\edXsolution{ A transformation from $\R^n$ to $\R^m$ has standard matrix of size $m \times n$. 
% If $A$ is the standard matrix for a transformation, $T: \R^n \rightarrow \R^m$, then for a vector $v\in\R^n$, $T(v)$ corresponds to $Av$.  Since $v$ has $n$ entries, $A$ needs to have $n$ columns.   Also, since $T$ outputs a vector in $\R^m$, we see that $A$ needs to have $m$ rows.
}
\endedxproblem


\beginedxproblem{Product Sizes}{\dpa1}

What size is $C_1C_2$?  


\edXabox{type="multichoice" expect="4 x 3" options="4 x 7","4 x 3","3 x 4","7 x 3","7 x 7","Not defined"}

What size is $C_2C_1$?  

\edXabox{type="multichoice" expect="Not defined" options="4 x 7","4 x 3","3 x 4","7 x 3","7 x 7","Not defined"}

\edXsolution{ The matrix $C_1C_2$ is the standard matrix for $T_1\circ T_2$, which is a linear transformation from $\R^3$ to $\R^4$.  Therefore $C_1C_2$ is a $4 \times 3$ matrix.\\

The number of columns of $C_2$ is not equal to the number of rows of $C_1$, and thus $C_2C_1$ is undefined.

}
\endedxproblem


\beginedxproblem{Composing with Identity Transformation}{\dpa2}

Suppose $S: \R^n \rightarrow \R^m$ is a linear transformation.
Let $T: \R^n \rightarrow \R^n$ be the identity transformation (recall that this means 
$T(v) = v$ for all $v\in \R^n$).  

Which of the following is true?

\edXabox{type="multichoice" expect="$S\circ T = S$" options="$S\circ T = T$","$S\circ T = S$","$T\circ S = T$","$T\circ S = S$"}


\edXsolution{ First, $T\circ S$ is undefined because $S$ outputs a vector in $\R^m$, and the domain of $T$ is $\R^n$.  Now, for every vector $v\in \R^n$, $S\circ T(v)=S(T(v))=S(v)$ because $T$ acts as the identity transformation.  Therefore $S\circ T=S$.

}
\endedxproblem

\beginedxproblem{Multiplying by Identity Matrix}{\dpa1}


Given the above scenario, let $A$ be the standard matrix for $S$.  Recall that the $n\times n$ identity matrix
$I_n$ is the standard matrix for $T$.  Which of the following is true?

\edXabox{type="multichoice" expect="$AI_n = A$" options="$AI_n = A$","$I_nA = A$","Both are true"}


\edXsolution{
$AI_n$ is the standard matrix for $S\circ T$ (from the above scenario) and from the previous question, we have $S\circ T=S$.  Thus, $AI_n$ equals the standard matrix for $S$, which is $A$.


Since $I_n$ has $n$ columns and $A$ has $m$ rows, $I_nA = A$ is undefined.  
}

\endedxproblem



\endedxvertical



\beginedxvertical{Calculating the Product}


\beginedxtext{Identity Matrix Properties}

The previous problems show the following:

{\keya{\bf{Proposition.}}}  
For any $m\times n$ matrix $A$, we have $AI_n = A$.  Similarly, $I_m A = A$.  

\endedxtext



\doedxvideo{Calculating the Product}{QbFZTxWh_9w}



\endedxvertical



\beginedxvertical{Product Practice}


\beginedxtext{Definition of Matrix Product}

{\keya{\bf{Definition.}}}  
If $A$ is an $m\times n$ matrix, and $B$ is an $n\times p$ matrix, then $AB$ is the $m\times p$ matrix
whose $i$th column is $A$ times the $i$th column of $B$.  

\endedxtext



\beginedxproblem{Which product?}{\dpa1}

Consider the matrices
\[ C = \left[\begin{array}{cc} 1 & -1 \\ 0 & 2  \\ -1 & 1  \end{array} \right]. \]
and 
\[ D = \left[\begin{array}{ccc} 1 & 2 & 3 \\ 0 & 1 & 1 \\ -1 & 4 & 3  \end{array} \right] \]

Of $CD$ and $DC$, which matrix product is defined?  

\edXabox{expect="DC" options="CD","DC","Both are defined"}


\edXsolution{ Since $D$ has 3 rows, and $C$ has only 2 columns, $CD$ is undefined.  But, $C$ has 3 rows, and $D$ has 3 columns, and thus the product $DC$ is defined.

}

\endedxproblem



\beginedxproblem{Compute the Product}{\dpa3}

From the problem above, enter the product which is defined.  (If both are, you may enter either one.)  

 
\input{matrixentry.tex}

\edXabox{type="custom" cfn="MatrixEntry" expect="[[-2,6],[-1,3],[-4,12]]"}

\edXsolution{We find \[ DC = \left[\begin{array}{cc} 1+0-3 & -1+4+3 \\ 0+0-1& 0+2+1 \\ -1+0-3 & 1+8+3  \end{array} \right] = \left[\begin{array}{cc} -2 & 6 \\ -1& 3 \\ -4 & 12  \end{array} \right]. \]

}

\endedxproblem




\beginedxproblem{Compute the Products}{\dpa1}

Let $A =  \left[\begin{array}{cc} 1 & -1 \\ 2 & 0  \end{array} \right] $
and $B = \left[\begin{array}{cc} 0 & 3 \\ 1 & 2  \end{array} \right] $.
 
\input{matrixentry.tex}

What is $AB$?  

\edXabox{type="custom" cfn="MatrixEntry" expect="[[-1,1],[0,6]]"}

What is $BA$?  

\edXabox{type="custom" cfn="MatrixEntry" expect="[[6,0],[5,-1]]"}


Is $AB$ the same as $BA$?

\edXabox{expect="No" options="Yes","No"}


\edXsolution{\[ AB = \left[\begin{array}{cc} 0+-1 & 3-2 \\ 0+0 & 6+0  \end{array} \right]
= \left[\begin{array}{cc} -1 & 1 \\ 0 & 6  \end{array} \right].  \]\\

\[ BA = \left[\begin{array}{cc} 0+6 & 0+0 \\ 1+4 & -1+0  \end{array} \right] 
= \left[\begin{array}{cc} 6 & 0 \\ 5 & -1  \end{array} \right].\]\\

We observe that $AB\neq BA$.

}

\endedxproblem





\endedxvertical

\beginedxvertical{Properties of Matrix Multiplication}



\doedxvideo{Commutative?  Associative?}{D80IuF4bedo}


\beginedxtext{Associativity of Multiplication}

{\keya{\bf{Proposition.}}}  
If $A$ is an $m\times n$ matrix, $B$ is an $n\times p$ matrix, and $C$ is a $p\times q$ matrix,
then $A(BC) = (AB)C$.  In other words, matrix multiplication is associative.  

\endedxtext


\endedxvertical



\beginedxvertical{Applying the Fundamental Fact of Matrix Multiplication}


\doedxvideo{A Proposition}{asgBUVRSvjE}


\beginedxtext{A Proposition about Matrix Multiplication}

{\keya{\bf{Proposition.}}}  
If $A$ is an $m\times n$ matrix and $B$ is an $n\times p$ matrix, and the columns of $B$ are
linearly dependent, then the columns of $AB$ must be linearly dependent. 

\endedxtext




\beginedxproblem{Linearly Independent?}{\dpa1}

     

True or false: If $A$ is an $m\times n$ matrix and $B$ is an $n\times p$ matrix, and the columns of $B$ are
linearly independent, then the columns of $AB$ must be linearly independent. 


\edXabox{expect="False" options="True","False"}


\edXsolution{ Here is a counterexample: If $A$ is the zero matrix, then $AB$ is also the zero matrix, and thus the columns of $AB$ are linearly dependent.


 }

\endedxproblem

\endedxvertical



\beginedxvertical{Proving Another Proposition}



\beginedxproblem{Another Proposition 1}{\dpa1}


Over the next few problems, we're going to apply the same 
technique of translating matrix properties to linear transformation properties, and exploiting the
Fundamental Fact of Matrix Multiplication, 
to prove the following proposition:

{\keya{\bf{Proposition.}}}  
Suppose $A$ is an $m\times n$ matrix and $B$ is an $n\times p$ matrix. If the columns of $A$ are
linearly independent, and the columns of $B$ are linearly independent, then the columns of $AB$ are 
linearly independent. 


Let $A$ be the standard matrix for a linear transformation $T$, and let $B$ be the standard matrix
for a linear transformation $S$.  From the assumption that the columns of $A$ are linearly independent,
what can we conclude about $T$?

\edXabox{type="multichoice" expect="$T$ is into" options="$T$ is into","$T$ is not into","$T$ is onto","$T$ is not onto"}


\edXsolution{ We have proven that the columns of $A$ are linearly independent if and only if  $T$ is into.

}

\endedxproblem

\beginedxproblem{Another Proposition 2}{\dpa1}

Our goal is to show that the columns of $AB$ are linearly independent.  This desired conclusion is equivalent
to which of the following?

\edXabox{type="multichoice" expect="$T\circ S$ is into" options="$S\circ T$ is into","$S\circ T$ is onto","$T\circ S$ is into","$T\circ S$ is onto" }


\edXsolution{ We know that $AB$ is the standard matrix for the transformation $T\circ S$.  Thus, the columns of $AB$ are linearly independent if and only if $\text{Ker}(T\circ S)=\{\veco\}$ if and only if $T\circ S$ is into.

}

\endedxproblem


\endedxvertical



\beginedxvertical{Another Proposition Continued}

\beginedxproblem{Another Proposition 3}{\dpa1}

Translating the information about linearly independent columns into 
facts about linear transformations: We know that $T$ and $S$ are into, and we are trying to prove that
$T\circ S$ is into.  This is much easier than trying to show that the columns of the product $AB$ are linearly
independent directly!

In order to prove that $T\circ S$ is into, we should...  

\edXabox{type="multichoice" expect="show that if $u\ne v$, then $T\circ S(u) \ne T\circ S(v)$"  options="show that if $u=v$, then $T\circ S(u) = T\circ S(v)$","show that if $u\ne v$, then $T\circ S(u) \ne T\circ S(v)$" }


\edXsolution{ 
A transformation is into if it sends any two different input vectors to two different output vectors. 
Thus the second option is what we want to show.  
}

\endedxproblem

\beginedxproblem{Another Proposition 4}{\dpa1}

Now that we know exactly what we need to do, let's do it!

Suppose that $u\ne v$ (for vectors $u,v$ in the domain $\R^p$).  


\edXinline{We can then apply the fact that} 
\edXabox{expect="S is into" options="S is into","T is into" inline="1" size="10"}

to conclude that 

\edXabox{type="multichoice" expect="$S(u)\ne S(v)$" options="$T(u)=T(v)$","$T(u)\ne T(v)$","$S(u)=S(v)$","$S(u)\ne S(v)$" }






\edXsolution{ When applying $T\circ S$, we first apply $S$.  Thus, we first use the fact that $S$ is into to show that $S(u)\ne S(v)$.
}

\endedxproblem

\beginedxproblem{Another Proposition 5}{\dpa1}

\edXinline{We use the result of the previous problem, together with the fact that}
\edXabox{expect="T is into" options="S is into","T is into" inline="1" size="10"}

to give us our desired conclusion that  $T\circ S(u) \ne T\circ S(v)$.  Therefore $T\circ S$ is into,
and we have proven our proposition!



\edXsolution{From the previous proposition, we have that $S(u)\ne S(v)$.  Next, we are applying $T$, so we use the fact that $T$ is into to show that $T\circ S(u) \ne T\circ S(v)$.
}

\endedxproblem



\endedxvertical
